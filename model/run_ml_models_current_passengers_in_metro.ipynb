{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "metro_dataset = pd.read_csv(\"../dataset/metro_passenger_flow.csv\")\n",
    "# Perform one-hot encoding on station_name and line_number columns\n",
    "encoded_columns = pd.get_dummies(metro_dataset[['station_name', 'line_number']], dtype=int)\n",
    "\n",
    "# Replace the original columns with the encoded columns\n",
    "metro_dataset = pd.concat([metro_dataset.drop(['station_name', 'line_number'], axis=1), encoded_columns], axis=1, )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T12:52:38.020285100Z",
     "start_time": "2024-02-14T12:52:27.352266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_status = pd.read_csv(\"../dataset/train_status.csv\")\n",
    "sum_passenger = train_status.groupby('current_timestamp')['current_passenger'].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T12:58:05.957595400Z",
     "start_time": "2024-02-14T12:58:05.923250400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "grouped_metro_data = metro_dataset.groupby('timestamp').agg({\n",
    "    'input_count': 'sum',\n",
    "    'output_count': 'sum',\n",
    "    'crowed_time_rate': 'mean',\n",
    "    'is_weekend': 'mean',\n",
    "    'is_holiday': 'mean'\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:06:15.440538800Z",
     "start_time": "2024-02-14T13:06:15.423030200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "sum_passenger_df = sum_passenger.reset_index().rename(columns={'current_timestamp': 'timestamp',})\n",
    "# Merge the 'sum_passenger_df' DataFrame with the 'grouped_metro_data' DataFrame based on the 'timestamp' column\n",
    "columns_to_keep = ['timestamp', 'input_count', 'output_count', 'crowed_time_rate', 'is_weekend', 'is_holiday', 'current_passenger']\n",
    "merged_data = pd.merge(grouped_metro_data, sum_passenger_df, on='timestamp')\n",
    "passenger_dataset = merged_data[columns_to_keep]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:10:13.149687Z",
     "start_time": "2024-02-14T13:10:13.124361800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def update_crowded_rate(timestamp):\n",
    "    timestamp = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "    if timestamp.hour > 6 and timestamp.hour < 8:\n",
    "        return 0.8\n",
    "    elif timestamp.hour >= 8 and timestamp.hour < 12:\n",
    "        return 1.2\n",
    "    elif timestamp.hour >= 12 and timestamp.hour < 16:\n",
    "        return 1\n",
    "    elif timestamp.hour >= 16 and timestamp.hour < 20:\n",
    "        return 1.2\n",
    "    else:\n",
    "        return 0.8\n",
    "\n",
    "passenger_dataset['timestamp'] = passenger_dataset['timestamp'].apply(update_crowded_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:11:58.518382700Z",
     "start_time": "2024-02-14T13:11:58.505622200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:12:08.628955200Z",
     "start_time": "2024-02-14T13:11:58.991446200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 51.65299131592512\n",
      "XGBoost R-squared: 0.8486811157062791\n",
      "Linear Regression RMSE: 53.612635848832205\n",
      "Linear Regression R-squared: 0.8369816492029062\n",
      "Random Forest Regression RMSE: 48.36787373133901\n",
      "Random Forest Regression R-squared: 0.8673167294790962\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(passenger_dataset, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract the target column (current_in_line_passengers)\n",
    "train_target = train_data['current_passenger']\n",
    "val_target = val_data['current_passenger']\n",
    "test_target = test_data['current_passenger']\n",
    "# Perform polynomial feature transformation\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "train_data_poly = poly.fit_transform(train_data.drop('current_passenger', axis=1))\n",
    "val_data_poly = poly.transform(val_data.drop('current_passenger', axis=1))\n",
    "test_data_poly = poly.transform(test_data.drop('current_passenger', axis=1))\n",
    "# Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(train_data_poly, train_target)\n",
    "linear_predictions = linear_model.predict(val_data_poly)\n",
    "linear_rmse = np.sqrt(mean_squared_error(val_target, linear_predictions))\n",
    "linear_r2 = r2_score(val_target, linear_predictions)\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='neg_root_mean_squared_error', cv=3)\n",
    "xgb_grid.fit(train_data_poly, train_target)\n",
    "xgb_model = xgb_grid.best_estimator_\n",
    "xgb_predictions = xgb_model.predict(val_data_poly)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(val_target, xgb_predictions))\n",
    "xgb_r2 = r2_score(val_target, xgb_predictions)\n",
    "# Random Forest Regression\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, scoring='neg_root_mean_squared_error', cv=3)\n",
    "rf_grid.fit(train_data_poly, train_target)\n",
    "rf_model = rf_grid.best_estimator_\n",
    "rf_predictions = rf_model.predict(val_data_poly)\n",
    "rf_rmse = np.sqrt(mean_squared_error(val_target, rf_predictions))\n",
    "rf_r2 = r2_score(val_target, rf_predictions)\n",
    "\n",
    "# Save the models and their RMSE values\n",
    "models = {\n",
    "    'XGBoost': xgb_model,\n",
    "    'Linear Regression': linear_model,\n",
    "    'Random Forest Regression': rf_model\n",
    "}\n",
    "\n",
    "rmse_values = {\n",
    "    'XGBoost': xgb_rmse,\n",
    "    'Linear Regression': linear_rmse,\n",
    "    'Random Forest Regression': rf_rmse\n",
    "}\n",
    "\n",
    "r2_scores = {\n",
    "    'Linear Regression': linear_r2,\n",
    "    'Random Forest Regression': rf_r2,\n",
    "    'XGBoost': xgb_r2\n",
    "}\n",
    "\n",
    "# Print the RMSE values\n",
    "for model_name, rmse in rmse_values.items():\n",
    "    r2 = r2_scores[model_name]\n",
    "    print(f\"{model_name} RMSE: {rmse}\")\n",
    "    print(f\"{model_name} R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"current_passengers_model_xgb.pkl\"\n",
    "# save\n",
    "pickle.dump(xgb_model, open(file_name, \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T13:32:40.406373700Z",
     "start_time": "2024-02-14T13:32:40.387431700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
