{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:05:28.340616700Z",
     "start_time": "2024-02-14T14:04:26.260813100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 4.189786217322767\n",
      "XGBoost R-squared: 0.8494530582315127\n",
      "Linear Regression RMSE: 4.14897281750039\n",
      "Linear Regression R-squared: 0.8523717780563899\n",
      "Random Forest Regression RMSE: 4.403256383005105\n",
      "Random Forest Regression R-squared: 0.8337214775465287\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "metro_dataset = pd.read_csv(\"../dataset/metro_passenger_flow_normal_rate.csv\")\n",
    "# Perform one-hot encoding on station_name and line_number columns\n",
    "encoded_columns = pd.get_dummies(metro_dataset[['station_name', 'line_number']], dtype=int)\n",
    "\n",
    "# Replace the original columns with the encoded columns\n",
    "metro_dataset = pd.concat([metro_dataset.drop(['station_name', 'line_number'], axis=1), encoded_columns], axis=1, )\n",
    "\n",
    "# Print the updated dataset\n",
    "metro_dataset['is_crowed_station'] = metro_dataset['is_crowed_station'].astype(int)\n",
    "metro_dataset\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def update_crowded_rate(timestamp):\n",
    "    timestamp = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "    if timestamp.hour > 6 and timestamp.hour < 8:\n",
    "        return 0.8\n",
    "    elif timestamp.hour >= 8 and timestamp.hour < 12:\n",
    "        return 1.2\n",
    "    elif timestamp.hour >= 12 and timestamp.hour < 16:\n",
    "        return 1\n",
    "    elif timestamp.hour >= 16 and timestamp.hour < 20:\n",
    "        return 1.2\n",
    "    else:\n",
    "        return 0.8\n",
    "\n",
    "\n",
    "metro_dataset['timestamp'] = metro_dataset['timestamp'].apply(update_crowded_rate)\n",
    "train_data, test_data = train_test_split(metro_dataset, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract the target column (input_count)\n",
    "train_target = train_data['input_count']\n",
    "val_target = val_data['input_count']\n",
    "test_target = test_data['input_count']\n",
    "# Perform polynomial feature transformation\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "train_data_poly = poly.fit_transform(train_data.drop('input_count', axis=1))\n",
    "val_data_poly = poly.transform(val_data.drop('input_count', axis=1))\n",
    "test_data_poly = poly.transform(test_data.drop('input_count', axis=1))\n",
    "# Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(train_data_poly, train_target)\n",
    "linear_predictions = linear_model.predict(val_data_poly)\n",
    "linear_rmse = np.sqrt(mean_squared_error(val_target, linear_predictions))\n",
    "linear_r2 = r2_score(val_target, linear_predictions)\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='neg_root_mean_squared_error', cv=3)\n",
    "xgb_grid.fit(train_data_poly, train_target)\n",
    "xgb_model = xgb_grid.best_estimator_\n",
    "xgb_predictions = xgb_model.predict(val_data_poly)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(val_target, xgb_predictions))\n",
    "xgb_r2 = r2_score(val_target, xgb_predictions)\n",
    "# Random Forest Regression\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, scoring='neg_root_mean_squared_error', cv=3)\n",
    "rf_grid.fit(train_data_poly, train_target)\n",
    "rf_model = rf_grid.best_estimator_\n",
    "rf_predictions = rf_model.predict(val_data_poly)\n",
    "rf_rmse = np.sqrt(mean_squared_error(val_target, rf_predictions))\n",
    "rf_r2 = r2_score(val_target, rf_predictions)\n",
    "\n",
    "# Save the models and their RMSE values\n",
    "models = {\n",
    "    'XGBoost': xgb_model,\n",
    "    'Linear Regression': linear_model,\n",
    "    'Random Forest Regression': rf_model\n",
    "}\n",
    "\n",
    "rmse_values = {\n",
    "    'XGBoost': xgb_rmse,\n",
    "    'Linear Regression': linear_rmse,\n",
    "    'Random Forest Regression': rf_rmse\n",
    "}\n",
    "\n",
    "r2_scores = {\n",
    "    'Linear Regression': linear_r2,\n",
    "    'Random Forest Regression': rf_r2,\n",
    "    'XGBoost': xgb_r2\n",
    "}\n",
    "\n",
    "# Print the RMSE values\n",
    "for model_name, rmse in rmse_values.items():\n",
    "    r2 = r2_scores[model_name]\n",
    "    print(f\"{model_name} RMSE: {rmse}\")\n",
    "    print(f\"{model_name} R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "               station_name  input_poisson\n0      station_name_Tajrish      34.575453\n1     station_name_Shariati      11.737076\n2     station_name_Beheshti      11.737076\n3       station_name_Dowlat      11.737076\n4   station_name_Mohamadieh      11.737076\n5     station_name_Kahrizak       0.000000\n6        station_name_Sanat      34.782065\n7      station_name_Valiasr      11.737076\n8     station_name_Theather      11.737076\n9   station_name_Mohamadieh      11.737076\n10      station_name_Heravi      11.737076\n11       station_name_Basij       0.000000\n12     station_name_Sattari      34.486114\n13     station_name_Valiasr      11.737076\n14       station_name_Jahad      11.737076\n15    station_name_Beheshti      11.737076\n16      station_name_Heravi      11.737076\n17       station_name_Ghaem       0.000000\n18       station_name_Azadi      33.409454\n19    station_name_Theather      11.737076\n20    station_name_ferdowsi      11.737076\n21      station_name_Dowlat      11.737076\n22    station_name_Shemiran      11.737076\n23      station_name_Booali       0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station_name</th>\n      <th>input_poisson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>station_name_Tajrish</td>\n      <td>34.575453</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>station_name_Shariati</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>station_name_Beheshti</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>station_name_Dowlat</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>station_name_Mohamadieh</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>station_name_Kahrizak</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>station_name_Sanat</td>\n      <td>34.782065</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>station_name_Valiasr</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>station_name_Theather</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>station_name_Mohamadieh</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>station_name_Heravi</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>station_name_Basij</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>station_name_Sattari</td>\n      <td>34.486114</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>station_name_Valiasr</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>station_name_Jahad</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>station_name_Beheshti</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>station_name_Heravi</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>station_name_Ghaem</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>station_name_Azadi</td>\n      <td>33.409454</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>station_name_Theather</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>station_name_ferdowsi</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>station_name_Dowlat</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>station_name_Shemiran</td>\n      <td>11.737076</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>station_name_Booali</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson_input_estimation = pd.DataFrame(columns=['station_name', 'input_poisson'])\n",
    "from dataset.stations import *\n",
    "poisson_input_estimation_dict = {\"station_name\": [], \"input_poisson\": []}\n",
    "for line_name, stations in Lines.items():\n",
    "    for station in stations:\n",
    "        s = \"station_name_\" + station\n",
    "        df = metro_dataset[metro_dataset[s] == 1]\n",
    "        poly_ = poly.transform(df.drop('input_count', axis=1))\n",
    "        average_station = poly_.mean(axis=0).reshape(1, -1)\n",
    "        input_poisson = rf_model.predict(average_station)\n",
    "        poisson_input_estimation_dict['station_name'].append(s)\n",
    "        poisson_input_estimation_dict['input_poisson'].append(input_poisson.item())\n",
    "poisson_input_estimation_df = pd.DataFrame(poisson_input_estimation_dict)\n",
    "poisson_input_estimation_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:05:31.744113700Z",
     "start_time": "2024-02-14T14:05:31.141384200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 5.549399328741542\n",
      "XGBoost R-squared: 0.6452154635011762\n",
      "Linear Regression RMSE: 5.418928775386373\n",
      "Linear Regression R-squared: 0.6617018571619979\n",
      "Random Forest Regression RMSE: 5.469949181067125\n",
      "Random Forest Regression R-squared: 0.6553015654935451\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "metro_dataset = pd.read_csv(\"../dataset/metro_passenger_flow_normal_rate.csv\")\n",
    "# Perform one-hot encoding on station_name and line_number columns\n",
    "encoded_columns = pd.get_dummies(metro_dataset[['station_name', 'line_number']], dtype=int)\n",
    "\n",
    "# Replace the original columns with the encoded columns\n",
    "metro_dataset = pd.concat([metro_dataset.drop(['station_name', 'line_number'], axis=1), encoded_columns], axis=1, )\n",
    "\n",
    "# Print the updated dataset\n",
    "metro_dataset['is_crowed_station'] = metro_dataset['is_crowed_station'].astype(int)\n",
    "metro_dataset\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def update_crowded_rate(timestamp):\n",
    "    timestamp = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "    if timestamp.hour > 6 and timestamp.hour < 8:\n",
    "        return 0.8\n",
    "    elif timestamp.hour >= 8 and timestamp.hour < 12:\n",
    "        return 1.2\n",
    "    elif timestamp.hour >= 12 and timestamp.hour < 16:\n",
    "        return 1\n",
    "    elif timestamp.hour >= 16 and timestamp.hour < 20:\n",
    "        return 1.2\n",
    "    else:\n",
    "        return 0.8\n",
    "\n",
    "\n",
    "metro_dataset['timestamp'] = metro_dataset['timestamp'].apply(update_crowded_rate)\n",
    "train_data, test_data = train_test_split(metro_dataset, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract the target column (output_count)\n",
    "train_target = train_data['output_count']\n",
    "val_target = val_data['output_count']\n",
    "test_target = test_data['output_count']\n",
    "# Perform polynomial feature transformation\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "train_data_poly = poly.fit_transform(train_data.drop('output_count', axis=1))\n",
    "val_data_poly = poly.transform(val_data.drop('output_count', axis=1))\n",
    "test_data_poly = poly.transform(test_data.drop('output_count', axis=1))\n",
    "# Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(train_data_poly, train_target)\n",
    "linear_predictions = linear_model.predict(val_data_poly)\n",
    "linear_rmse = np.sqrt(mean_squared_error(val_target, linear_predictions))\n",
    "linear_r2 = r2_score(val_target, linear_predictions)\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='neg_root_mean_squared_error', cv=3)\n",
    "xgb_grid.fit(train_data_poly, train_target)\n",
    "xgb_model = xgb_grid.best_estimator_\n",
    "xgb_predictions = xgb_model.predict(val_data_poly)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(val_target, xgb_predictions))\n",
    "xgb_r2 = r2_score(val_target, xgb_predictions)\n",
    "# Random Forest Regression\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, scoring='neg_root_mean_squared_error', cv=3)\n",
    "rf_grid.fit(train_data_poly, train_target)\n",
    "rf_model = rf_grid.best_estimator_\n",
    "rf_predictions = rf_model.predict(val_data_poly)\n",
    "rf_rmse = np.sqrt(mean_squared_error(val_target, rf_predictions))\n",
    "rf_r2 = r2_score(val_target, rf_predictions)\n",
    "\n",
    "# Save the models and their RMSE values\n",
    "models = {\n",
    "    'XGBoost': xgb_model,\n",
    "    'Linear Regression': linear_model,\n",
    "    'Random Forest Regression': rf_model\n",
    "}\n",
    "\n",
    "rmse_values = {\n",
    "    'XGBoost': xgb_rmse,\n",
    "    'Linear Regression': linear_rmse,\n",
    "    'Random Forest Regression': rf_rmse\n",
    "}\n",
    "\n",
    "r2_scores = {\n",
    "    'Linear Regression': linear_r2,\n",
    "    'Random Forest Regression': rf_r2,\n",
    "    'XGBoost': xgb_r2\n",
    "}\n",
    "\n",
    "# Print the RMSE values\n",
    "for model_name, rmse in rmse_values.items():\n",
    "    r2 = r2_scores[model_name]\n",
    "    print(f\"{model_name} RMSE: {rmse}\")\n",
    "    print(f\"{model_name} R-squared: {r2}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:06:46.558429900Z",
     "start_time": "2024-02-14T14:05:33.982263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "               station_name  output_poisson\n0      station_name_Tajrish        0.027595\n1     station_name_Shariati        9.489689\n2     station_name_Beheshti       16.942271\n3       station_name_Dowlat       17.068766\n4   station_name_Mohamadieh       17.047023\n5     station_name_Kahrizak       22.092112\n6        station_name_Sanat        0.027595\n7      station_name_Valiasr       17.256691\n8     station_name_Theather       17.082848\n9   station_name_Mohamadieh       17.047023\n10      station_name_Heravi        9.489689\n11       station_name_Basij       23.021595\n12     station_name_Sattari        0.027595\n13     station_name_Valiasr       17.256691\n14       station_name_Jahad        9.489689\n15    station_name_Beheshti       16.942271\n16      station_name_Heravi        9.489689\n17       station_name_Ghaem       29.430598\n18       station_name_Azadi        0.027595\n19    station_name_Theather       17.082848\n20    station_name_ferdowsi        9.489689\n21      station_name_Dowlat       17.068766\n22    station_name_Shemiran        9.489689\n23      station_name_Booali       29.826478",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station_name</th>\n      <th>output_poisson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>station_name_Tajrish</td>\n      <td>0.027595</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>station_name_Shariati</td>\n      <td>9.489689</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>station_name_Beheshti</td>\n      <td>16.942271</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>station_name_Dowlat</td>\n      <td>17.068766</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>station_name_Mohamadieh</td>\n      <td>17.047023</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>station_name_Kahrizak</td>\n      <td>22.092112</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>station_name_Sanat</td>\n      <td>0.027595</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>station_name_Valiasr</td>\n      <td>17.256691</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>station_name_Theather</td>\n      <td>17.082848</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>station_name_Mohamadieh</td>\n      <td>17.047023</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>station_name_Heravi</td>\n      <td>9.489689</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>station_name_Basij</td>\n      <td>23.021595</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>station_name_Sattari</td>\n      <td>0.027595</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>station_name_Valiasr</td>\n      <td>17.256691</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>station_name_Jahad</td>\n      <td>9.489689</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>station_name_Beheshti</td>\n      <td>16.942271</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>station_name_Heravi</td>\n      <td>9.489689</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>station_name_Ghaem</td>\n      <td>29.430598</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>station_name_Azadi</td>\n      <td>0.027595</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>station_name_Theather</td>\n      <td>17.082848</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>station_name_ferdowsi</td>\n      <td>9.489689</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>station_name_Dowlat</td>\n      <td>17.068766</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>station_name_Shemiran</td>\n      <td>9.489689</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>station_name_Booali</td>\n      <td>29.826478</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset.stations import *\n",
    "poisson_input_estimation_dict = {\"station_name\": [], \"output_poisson\": []}\n",
    "for line_name, stations in Lines.items():\n",
    "    for station in stations:\n",
    "        s = \"station_name_\" + station\n",
    "        df = metro_dataset[metro_dataset[s] == 1]\n",
    "        poly_ = poly.transform(df.drop('output_count', axis=1))\n",
    "        average_station = poly_.mean(axis=0).reshape(1, -1)\n",
    "        output_poisson = rf_model.predict(average_station)\n",
    "        poisson_input_estimation_dict['station_name'].append(s)\n",
    "        poisson_input_estimation_dict['output_poisson'].append(output_poisson.item())\n",
    "poisson_output_estimation = pd.DataFrame(poisson_input_estimation_dict)\n",
    "poisson_output_estimation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T14:07:26.232950800Z",
     "start_time": "2024-02-14T14:07:25.982526900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
